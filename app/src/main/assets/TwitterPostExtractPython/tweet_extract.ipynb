{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"V49B6qBjE2x3YWyKqgq0tOklZ\"\n",
    "consumer_secret = \"jm4SrEiidBalOqRI7D5IEghz56rvEGpcgscvRoyYrbnaPCnmtB\"\n",
    "access_key = \"1522366452384161792-QODP9Czf4xgRaz2UnXKhuhtikXEChE\"\n",
    "access_secret = \"khDtX6g1QGMdGe8cZNYOaqXwDNJ2zgXLBGnuJEHPcnj9d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start searching key words\n",
      "tweets extract doned\n",
      "72 item processedst 15\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening doneedst 30\n",
      "Start getting statuses\n",
      "Getting tweet statuses: 891\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweet statuses: 1786\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweet statuses: 2677\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet data has been obtained\n",
      "detailed data has been obtained\n"
     ]
    }
   ],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Define the search term and the date_since date as variables\n",
    "search_words = ['University', 'ANU', 'Sport', 'Australia', 'ANU campus', \n",
    "                'food', 'Assignment', 'Exams', 'Mental health', 'University students', \n",
    "                'University Research', 'Computer sciense', 'Natrual science', 'Student life', 'Music', \n",
    "                'Jazz music', 'Pop music', 'Software engineer', 'Canberra', 'Car', \n",
    "                'Basketball', 'Football', 'Rugby', 'handball', 'Athletics', \n",
    "                'Drawing', 'Anime', 'Japanese Anime', 'Love', 'Crush']\n",
    "\n",
    "# Collect tweets\n",
    "print('start searching key words')\n",
    "i = 1\n",
    "tweets = []\n",
    "for sw in search_words:\n",
    "    tweets.append(tw.Cursor(api.search_tweets,\n",
    "              q='123',\n",
    "              lang=\"en\").items(100))\n",
    "    print(str(i) + \" key word searched\", end = '\\r')\n",
    "    i += 1\n",
    "print('', end = '\\r')\n",
    "print('tweets extract done')\n",
    "# flatten the list\n",
    "\n",
    "i = 1\n",
    "flat_list = []\n",
    "for sublist in tweets:\n",
    "    print('flattening the list ' + str(i), end = '\\r')\n",
    "    i += 1\n",
    "    o = 0\n",
    "    for item in sublist:\n",
    "        print(str(o) + ' item processed', end = '\\r')\n",
    "        flat_list.append(item)\n",
    "        o += 1\n",
    "print('', end = '\\r')\n",
    "tweets = flat_list\n",
    "tweets_data= []\n",
    "print('flattening done')\n",
    "\n",
    "print('Start getting statuses')\n",
    "i = 1;\n",
    "for t in tweets:\n",
    "    try:\n",
    "        tweets_data.append(api.get_status(t.id, tweet_mode=\"extended\"))\n",
    "        print(\"Getting tweet statuses: \"+str(i) , end='\\r')\n",
    "        i += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "print('', end = '\\r')\n",
    "print('tweet data has been obtained')\n",
    "i = 1\n",
    "tweet_list = []\n",
    "for td in tweets_data:\n",
    "    data = [td.user.screen_name, #author\n",
    "      td.full_text, #content\n",
    "      td.favorite_count, #likes_count\n",
    "      td.author.created_at] # Time\n",
    "    tweet_list.append(data)\n",
    "    print(\"Getting detailed data: \"+str(i) , end='\\r')\n",
    "    i += 1\n",
    "print('', end = '\\r')\n",
    "print(\"detailed data has been obtained\")\n",
    "\n",
    "i = 1\n",
    "with open('tweets_data', 'wb') as fp:\n",
    "    pickle.dump(tweets_data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a very good platform to earn money\n",
      "#CoinSwitch @coinswitchkuber https://t.co/J56TptDtHL\n"
     ]
    }
   ],
   "source": [
    "with open ('tweets_data', 'rb') as fp:\n",
    "    tweet_list = pickle.load(fp)\n",
    "print(tweet_list[0].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#pretty print method\n",
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    j = \"\\n\" + (level-1)*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for subelem in elem:\n",
    "            indent(subelem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = j\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = j\n",
    "    return elem\n",
    "\n",
    "#root element\n",
    "root = ET.Element('Post', {})\n",
    "\n",
    "post_count = 1\n",
    "#post sub-element\n",
    "for tl in tweet_list:\n",
    "    post = ET.SubElement(root, \"post\", {'id' : str(post_count)})\n",
    "    post_count = post_count + 1\n",
    "    \n",
    "    author = ET.SubElement(post, 'author')\n",
    "    content = ET.SubElement(post, 'content')\n",
    "    likes_count = ET.SubElement(post, 'likes_count')\n",
    "    time = ET.SubElement(post, 'time')\n",
    "    comment = ET.SubElement(post, 'comment')\n",
    "    author.text = str(tl.user.screen_name)\n",
    "    content.text = str(tl.full_text)\n",
    "    likes_count.text = str(tl.favorite_count)\n",
    "    time.text = str(tl.author.created_at)\n",
    "\n",
    "#write to file\n",
    "tree = ET.ElementTree(indent(root))\n",
    "tree.write('posts.xml', xml_declaration=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
